---
title: "final_project_dolgov"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Анализ качества перевода англо-французских текстов с “ложными друзьями переводчика”, производимого разными seq2seq моделями.


## Цели исследования, гипотезы, которые будут тестироваться.

В качестве цели исследования я выбрал 

Эта тема мне была интересна столько, сколько я учил языки - так называемые "ложные друзья переводчика". 
Ложные друзья переводчика (или межъязыковые омонимы / паронимы) - это слова в двух языках, похожие по написанию или произношению, но отличающиеся в значении.

Поскольку язык - невероятно сложная система, которая зависит не только от своих внутренних правил, но и от других языков, перевод - многогранный и тяжелый труд. Несмотря на свое название, ложные друзья в этом не помогают - наоборот, они могут приводить к неправильному пониманию и переводу текста. 
Ввиду того, что мы уже наблюдаем серьезное развитие систем машинного перевода, я считаю важным изучить их способность переводить такие слова, которые могут легко ввести в заблуждение человека. 

В качестве моделей машинного перевода, которые будут использоваться для сравнения качества перевода, я выбрал MBart, NLLB и ALIGN. Все три модели могут переводить как с английского на французский, так и наоборот.


### Гипотезы

Я выделил следующую нулевую гипотезу: 

  H0: Качество такого перевода не зависит от модели.

Она имеет место быть, поскольку современные модели, обученные на качественных двуязычных датасетах, вполне могут обладать достаточными способностями к пониманию контекста, чтобы правильно переводить предложения, не теряя качества на "ложных друзьях".

Альтернативных гипотез всего три: 

  H1: Качество такого перевода выше у модели архитектуры MBart.
  H1: Качество такого перевода выше у модели архитектуры NLLB.
  H1: Качество такого перевода выше у модели архитектуры ALIGN.

По одной гипотезе выделено на случай, если одна из моделей покажет качество лучше, чем другие. Такое вполне реально, ведь датасеты могут различаться качеством, размером и представленностью "друзей". 


## Предыдущие исследования.

Тема "ложных друзей переводчика", особенно в языковой паре французкий-английский, относительно слабо развита. 

Задача создания датасета межъязыковых паронимов с целью изучить или улучшить модели машинного перевода решается в статье Challenge Dataset of Cognates and False Friend Pairs from Indian Languages [1], но, как очевидно из названия, только для индийских языков. 

Существует также статья Automatic Identification of Cognates, False Friends, and Partial Cognates [2], в которой автор предлагает обособленный инструмент для автоматического определения "ложных друзей". Классификатор задумывался для улучшения моделей и систем машинного перевода, и был разработан для языковой пары французский-английский.

Однако, датасет, который авторы использовали для обучения классификатора, находится в закрытом доступе, а некоторые ссылки, предоставленные в работе, уже не работают. 


## Описание исходных данных. 

Таким образом, датасета, сфокусированного именно на "ложных друзьях" во французском и английском в открытом доступе нет, а потому я решил самостоятельно его собрать. 
Для этого я определил список таких пар и отобрал самые частотные из них (здесь частотность определена эвристически, на основе 8-и и 16-ти летнего опыта изучения французского и английского языков соответственно). 
Конкретные пары я парсил с нескольких сайтов[3][4][5], указанных в конце исследования, затем отбирал вручную. 
Итоговый размер датасета - 74 пары "друзей". 

Для каждой пары я составил по четыре предложения: 
- предложение на английском ()
- перевод на французский 
- предложение на французском 
- перевод на английский 

Затем, каждый перевод я оценил с помощью двух метрик - нормализованного расстояния Левенштейна и BLEU score. 
Расстояние Левенштейна дает общее понимание похожести двух строк, а BLEU показывает непосредственно качество перевода.

Переменные в датасете разделены на две части:
1. Данные для перевода:
  - en_fa - "ложный друг" на английском
  - fr_fa - "ложный друг" на французском
  - mode - направленность перевода - EnFr | FrEn
  - sent - исходное сообщение (язык зависит от направленности)
  - trans - сообщение, переведенное вручную 
  - trans_MBart - перевод модели MBart
  - trans_NLLB - перевод модели NLLB
  - trans_ALIGN - перевод модели ALIGN
  - POSent - позиция "друга" в предложении - "start" | "mid" | "end"
2. Метрики оценки машинного перевода:
  - Levenshtein_MBart 
  - BLEU_MBart 
  - Levenshtein_NLLB 
  - BLEU_NLLB 
  - Levenshtein_ALIGN 
  - BLEU_ALIGN 

Все переменные в первой части - категориальные (строковые), во второй - числовые, с плавающей точкой. 

```{r}
library(tidyverse)

data <- read.csv("data/final_project_data_dolgov.csv")
summary(data)
head(data)
```

## Методы анализа.

При анализе датасета я буду использовать следующие методы: 
- тесты ANOVA, T-test (статистический анализ)
- гистограммы, ящики с усами, кореллограмму (визуализация)
- фильтрование выбросов - слишком длинных и коротких предложений 


## Описательная статистика.

```{r position}
library(ggplot2)

p <- data %>%
  ggplot(aes(x=POSent)) +
  geom_histogram(stat="count") +
  ggtitle('Распределение позиции паронима')
p
```

Для начала стоит проверить, есть ли в датасете пустые элементы, или предложения, которые сильно длиннее или короче других? 
Оба этих критерия могут повлиять на среднее качество перевода. 

```{r length}
print(paste("Кол-во пустых строк:", sum(is.na(data))))

props <- prop.table(table(data$mode))[1]
print(paste("Соотношение предложений на английском и французском: ", props))

data$len_sent <- nchar(data$sent)
data$len_trans <- nchar(data$trans)

print(paste("Средняя длина исходных предложений: ", mean(data$len_sent)))
print(paste("Средняя длина переведенных предложений: ", mean(data$len_trans)))

hist_data <- data %>%
  pivot_longer(cols=(len_sent:len_trans), names_to="attr", values_to="length")

p <- hist_data %>%
  ggplot(aes(x=length, group=attr, fill=attr)) +
  geom_histogram(binwidth=1, alpha=0.5, position="identity") +
  scale_x_continuous(name = "Длина в символах",
                           breaks=seq(0, 80, 5)) +
        scale_y_continuous(name = "Кол-во предложений",
                           breaks=seq(0, 15, 1)) +
  ggtitle("Распределение длины предложений") +
  geom_vline(xintercept=mean(data$len_sent), size=1, colour="blue", linetype="dashed") +
  geom_vline(xintercept=mean(data$len_trans), size=1, colour="red", linetype="dashed")
p
```

В выборке пустых предложений или других пустых переменных нет, предложения представлены нормальным распределением длины как оригинальных, так и переведенных предложений. 
Среднее значение длины приблизительно равно 41 симв.

Соотношение предложений на обоих языках - ровно 50%. 

Далее стоит проанализировать представленные метрики. 

```{r metrics}
library(ggpubr)
box_data <- data %>%
  pivot_longer(cols=(c(Levenshtein_MBart, Levenshtein_NLLB, Levenshtein_ALIGN)), names_to="Levenshtein", values_to="value_lev") %>%
  pivot_longer(cols=(c(BLEU_MBart, BLEU_NLLB, BLEU_ALIGN)), names_to="BLEU", values_to="value_bleu")

lev_bp <- box_data %>%
 ggplot(aes(x=Levenshtein, y=value_lev, fill=Levenshtein)) +
 geom_boxplot() +
 labs(x = "", y = "") +
 theme_classic()

bleu_bp <- box_data %>%
 ggplot(aes(x=BLEU, y=value_bleu, fill=BLEU)) +
 geom_boxplot() +
 labs(x = "", y = "") +
 theme_classic()

arr <- ggarrange(lev_bp, bleu_bp, ncol=1, nrow=2)

annotate_figure(arr, top=text_grob("Анализ распределения метрик"))

print(paste("Общее среднее расстояние Левенштейна: ", mean(data$len_sent)))
```

```{r stats for metrics}
print("Статистическое распределение расстояния Левенштейна")
print("MBart")
print(summary(data$Levenshtein_MBart))
print("NLLB")
print(summary(data$Levenshtein_NLLB))
print("ALIGN")
print(summary(data$Levenshtein_ALIGN))

print("Статистическое распределение BLEU score")
print("MBart")
print(summary(data$BLEU_MBart))
print("NLLB")
print(summary(data$BLEU_NLLB))
print("ALIGN")
print(summary(data$BLEU_ALIGN))
```

Представленная статистика будет проанализирована в следующем разделе. 

Также имеет смысл проверить данные на предмет корелляции, причем как на корелляцию метрик между собой, так и на корелляцию метрик с другими переменными: длиной исходных предложений, длиной переводов, направлением перевода и позицией паронима в предложении. 

```{r}
library(corrplot)

data_for_cor <- data %>%
  select(
    Levenshtein_MBart, Levenshtein_NLLB, Levenshtein_ALIGN, 
    BLEU_MBart, BLEU_NLLB, BLEU_ALIGN,
    len_sent, len_trans, 
    mode, POSent
    ) %>%
  mutate(mode = ifelse(mode == "EnFr", 1, 0)) %>%
  mutate(POSent = ifelse(POSent == "start", 0,
                         ifelse(POSent == "mid", 1, 2)))
print(data_for_cor)

cor_matrix <- cor(data_for_cor)

corrplot(cor_matrix, type = "upper",  
         method = "circle",
         addCoef.col = "black",  
         tl.col = "black", tl.srt = 45)
```

Кореллограма показывает сильную корелляцию между метриками одного типа, и сильную отрицательную корелляцию между метриками разных видов. 
Что касается категориальных переменных, только одна из них имеет небольшую корелляцию с метрикой BLEU модели MBart. Остальные взаимодействуют только между собой: так, длина исходного предложения кореллирует с длиной перевода, а длина перевода - с направлением перевода.

О последних двух корелляциях можно сказать только то, что они доказывают успешность моделей в сохранении длины текста при его переводе. 
Также стоит учитывать, что в сравнении принимает участие французский и английский язык, причем французский известен своими сложными и многословными грамматическими структурами. Поэтому, можно предположить, что именно при переводе с английского на французский увеличивается длина перевода. 


## Количественные результаты.

(фреквентистская статистика, разведочный анализ, байесовская статистика и т.п.) и их лингвистическая (содержательная) интерпретация

Поскольку Н0 для этого исследования состоит в том, что между выбранными моделями нет существенной разницы в качестве перевода, а моделей три, имеет смысл применить дисперсионный анализ ANOVA. 
Необходимо понять, отличается ли среднее значение метрик какой-либо из моделей от общего среднего значения. 

В данном одностороннем ANOVA тесте в качестве независимой переменной будут выбраны названия метрик для трех моделей ("Levenshtein MBart", "Levenshtein NLLB", "Levenshtein ALIGN" и "BLEU MBart", "BLEU NLLB", "BLEU ALIGN" из переменных Levenshtein) и BLEU соответственно. 

Однако, прежде, чем проводить тест ANOVA, нужно убедиться, что дисперсия в метриках для всех трех моделей примерно одинаковая. Для этого можно провести тест Ливиня. 

Начнем с расстояния Левенштейна. 

```{r Levene Levenshtein}
library(car)

quantit_data <- box_data
quantit_data$Levenshtein <- factor(quantit_data$Levenshtein)

levene <- leveneTest(value_lev ~ Levenshtein, data=quantit_data)
levene
```

По результатам тестя Ливиня (высокое F-value и p-value < 0.05) видно, что дисперсия в группах расстояния Левенштейна разнится. 
Это значит, что применить one-way ANOVA нельзя - не выполняется допущение о гомогенности. 

В таком случае, целесообразно применить непараметрический аналог - тест Краскела-Уоллиса. 

```{r Kruskal-Wallis}

kruskal.test(value_lev ~ Levenshtein, data=quantit_data)
```

Тест Краскел-Уоллиса показал p-value сильно ниже, чем 0.05, что свидетельствует о значимом различии между моделями.  

Чтобы понять, как именно отличаются метрики моделей, нужно провести post-hoc test. 
В данном случае, нужны попарные t-test-ы с поправкой на множественные сравнения, например тест Уилкоксона. 


```{r post hoc Wilcoxon}
pairwise.wilcox.test(quantit_data$value_lev, quantit_data$Levenshtein, p.adj='BH')
```

Тест Уилкоксона показал низкие (< 0.05) p-value для пар Levenshtein_MBart - Levenshtein_ALIGN и Levenshtein_MBart - Levenshtein_NLLB. В то же время, между Levenshtein NLLB и ALIGN различия сравнительно незначительные. 
Опираясь на результаты этого теста, можно сделать вывод о том, что значимо отличается качество модели MBart. 

Возвращаясь к анализу средних и медианных значений расстояний Левенштейна на этой модели, мы видим, что MBart обладает самым высоким средним расстоянием Левенштейна - 0.23 против 0.17 и 0.16 у NLLB и ALIGN соответственно. 

Поскольку высокое расстояние Левенштейна свидетельствует о низкой похожести строк и, соответственно, низком качестве перевода, можно сделать промежуточный вывод о том, что MBart уступает по качеству NLLB и ALIGN, а из последней пары ALIGN обладает высшим качеством перевода. 

Теперь следует вернуться ко второй метрике оценки качества перевода - BLEU. 
Повторяя процедуру, стоит убедиться, что дисперсия в группах BLEU приблизительно равная. 

```{r Levene BLEU}
quantit_data$BLEU <- factor(quantit_data$BLEU)
levene <- leveneTest(value_bleu ~ BLEU, data=quantit_data)
levene
```

В отличие от аналогичного теста на метрике расстояния Левенштейна, тест на метрике BLEU показал сравнительно низкое F-value, а также высокое p-value (>0.05). 
Это значит, что дисперсия в группах BLEU не разнится, и можно применить one-way ANOVA - допущение о гомогенности выполняется.

```{r one-way ANOVA}
anova_ow <- aov(value_bleu ~ BLEU, data=quantit_data)
summary(anova_ow)
```

ANOVA тест показал относительно высокое F-value и низкое (< 0.05) p-value. Это значит, что Н0 об одинаковом качестве переводов можно отвергнуть, и перейти к post-hoc test-ам. 
Применим тест Тьюки. 

```{r one-way Tukey}
tukey_ow <- TukeyHSD(anova_ow)
tukey_ow
```

По итогам теста Тьюки низкие (< 0.05) p-value мы видим у пар BLEU_MBart - BLEU_ALIGN и BLEU_NLLB - BLEU_MBart, в то время как у пары BLEU_NLLB - BLEU_ALIGN p-value высокое. 
Это снова говорит о том, что NLLB и ALIGN примерно равны по качеству, а качество MBart в значимой степени отличается. 

Приведем среднее значение метрики BLEU для моделей: 
- MBart: 0.43
- NLLB: 0.53
- ALIGN: 0.56

Совместно с результатами статистических тестов, метрики во второй раз показывают преимущество переводов модели ALIGN, затем NLLB и в самом конце - MBart.


## Дискуссия.

Подводя итоги исследовательской работы, можно сделать четкий и конкретный вывод о модели, переводы которой обладают самым высоким качеством на основании расстояния Левенштейна и метрики BLEU: ALIGN. 
Из трех выбранных моделей, именно эта модель обладает самыми высокими (и низкими, в случае расстояния Левенштейна) средними метриками. 

Стоит, однако, сделать замечание о потенциальных улучшениях, которые могут повысить качество анализа. 

1. Поскольку работа учебная и проводилась в условиях ограниченных вычислительных способностей, модели были выбраны с соответствующе низким количеством параметров (75 млн у ALIGN, 1.3 млрд у NLLB и 610 млн у MBart). 
Качество перевода как правило улучшается при использовании больших моделей. 

2. В финальном датасете было использовано 74 пары "друзей переводчика". Хотя такого датасета достаточно, чтобы понять общую картину качества перевода моделей, большая выборка разных "друзей" безусловно поможет в лучшем понимании итогового различия. 

3. С учетом двух направлений перевода (фр - англ, англ - фр), в финальном датасете 74 * 2 = 148 строк. В качестве улучшения и продолжения работы можно написать / собрать / сгенерировать больше записей для датасета в целом, например, вместо 2 записей на одну пару "друзей" можно подготовить 4-6 больше записей. 

4. Интересное направление развития работы - сбор большего количества метаданных. В работе были проанализированы длина исходного предложения, перевода и расположение "друзей" в предложении. Этот список можно пополнить, например, частотой использования таких "друзей" в общении в целом. 

5. Наконец, итоговое предложение - с учетом успеха модели архитектуры ALIGN, которая была обучена на датасете opus, можно дообучить другие модели на этом же датасете, включая в обучающую выборку записи с "ложными друзьями". 


## Ссылки на материалы.

  1. Challenge Dataset of Cognates and False Friend Pairs from Indian Languages, Diptesh Kanojia et al. [https://aclanthology.org/2020.lrec-1.378.pdf]
  [https://www.thoughtco.com/french-english-false-cognates-faux-amis-1364675]
  2. Automatic Identification of Cognates, False Friends, and Partial Cognates, Oana Magdalena Frunza et al. [https://www.researchgate.net/publication/277297339_Automatic_Identification_of_Cognates_False_Friends_and_Partial_Cognates]
Сайты, с которых были взяты "ложные друзья":
  3. [https://www.thoughtco.com/faux-amis-vocabulary-1371249]
  4. [https://www.vidalingua.com/blog/faux-amis-anglais]
  5. [https://wallstreetenglish.fr/fiches-anglais/general/faux-amis-anglais]
